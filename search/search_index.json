{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":"<p>OpenPredict is a python package that helps data scientists to build, and publish prediction models in a FAIR and reproducible manner. It provides helpers for various steps of the process:</p> <ul> <li>A template to help user quickly bootstrap a new prediction project with the recommended structure (MaastrichtU-IDS/cookiecutter-openpredict-api)</li> <li>Helper function to easily save a generated model, its metadata, and the data used to generate it. It uses tools such as <code>dvc</code> and <code>mlem</code> to store large model outside of the git repository.</li> <li>Deploy API endpoints for retrieving predictions, which comply with the NCATS Biomedical Data Translator standards (Translator Reasoner API and BioLink model), using a decorator <code>@trapi_predict</code> to simply annotate the function that produces predicted associations for a given input entity</li> </ul> <p>Predictions are usually generated from machine learning models (e.g. predict disease treated by drug), but it can adapt to generic python function, as long as the input params and return object follow the expected structure.</p> <p>The package can be installed with <code>pip</code>:</p> <pre><code>pip install openpredict\n</code></pre>"},{"location":"getting-started/create-model/","title":"Create prediction model","text":""},{"location":"getting-started/create-model/#start-a-new-prediction-project","title":"\ud83c\udf6a Start a new prediction project","text":"<p>A template to help user quickly start a new prediction project with the recommended structure (MaastrichtU-IDS/cookiecutter-openpredict-api). It will ask you a few questions (e.g. the name of your project), and bootstrap a repository with everything ready to start developing your prediction models.</p> <p>Run these commands to install <code>cookiecutter</code> and generate your project:</p> <pre><code>pip install cookiecutter\ncookiecutter https://github.com/MaastrichtU-IDS/cookiecutter-openpredict-api\n</code></pre> <p>Once your project has been generated, follow the instructions in the generated <code>README.md</code> to run your project in development.</p>"},{"location":"getting-started/create-model/#save-a-generated-model","title":"\ud83d\udcbe Save a generated model","text":"<p>A helper function is provided to easily save a generated model, its metadata, and the data used to generate it. It uses tools such as <code>dvc</code> and <code>mlem</code> to store large model outside of the git repository.</p> <pre><code>from openpredict import save\nhyper_params = {\n'penalty': 'l2',\n'dual': False,\n'tol': 0.0001,\n'C': 1.0,\n'random_state': 100\n}\nsaved_model = save(\nmodel=clf,\npath=\"models/my_model\",\nsample_data=sample_data,\nhyper_params=hyper_params,\nscores=scores,\n)\n</code></pre>"},{"location":"getting-started/create-model/#define-the-prediction-endpoint","title":"\ud83d\udd2e Define the prediction endpoint","text":"<p>The <code>openpredict</code> package provides a decorator <code>@trapi_predict</code> to annotate your functions that generate predictions. The code for this package is in <code>src/openpredict/</code>.</p> <p>Predictions generated from functions decorated with <code>@trapi_predict</code> can easily be imported in the Translator OpenPredict API, exposed as an API endpoint to get predictions from the web, and queried through the Translator Reasoner API (TRAPI)</p> <pre><code>from openpredict import trapi_predict, PredictOptions, PredictOutput\n@trapi_predict(path='/predict',\nname=\"Get predicted targets for a given entity\",\ndescription=\"Return the predicted targets for a given entity: drug (DrugBank ID) or disease (OMIM ID), with confidence scores.\",\nedges=[\n{\n'subject': 'biolink:Drug',\n'predicate': 'biolink:treats',\n'object': 'biolink:Disease',\n},\n{\n'subject': 'biolink:Disease',\n'predicate': 'biolink:treated_by',\n'object': 'biolink:Drug',\n},\n],\nnodes={\n\"biolink:Disease\": {\n\"id_prefixes\": [\n\"OMIM\"\n]\n},\n\"biolink:Drug\": {\n\"id_prefixes\": [\n\"DRUGBANK\"\n]\n}\n}\n)\ndef get_predictions(\ninput_id: str, options: PredictOptions\n) -&gt; PredictOutput:\n# Add the code the load the model and get predictions here\npredictions = {\n\"hits\": [\n{\n\"id\": \"DB00001\",\n\"type\": \"biolink:Drug\",\n\"score\": 0.12345,\n\"label\": \"Leipirudin\",\n}\n],\n\"count\": 1,\n}\nreturn predictions\n</code></pre>"},{"location":"getting-started/deploy-api/","title":"Deploy the API","text":"<p>You will need to instantiate a <code>TRAPI</code> class to deploy a Translator Reasoner API serving a list of prediction functions that have been decorated with <code>@trapi_predict</code>. For example:</p> <pre><code>import logging\nfrom openpredict.config import settings\nfrom openpredict import TRAPI\nfrom my_model.predict import get_predictions\nlog_level = logging.ERROR\nif settings.DEV_MODE:\nlog_level = logging.INFO\nlogging.basicConfig(level=log_level)\npredict_endpoints = [ get_predictions ]\nopenapi_info = {\n\"contact\": {\n\"name\": \"Firstname Lastname\",\n\"email\": \"email@example.com\",\n# \"x-id\": \"https://orcid.org/0000-0000-0000-0000\",\n\"x-role\": \"responsible developer\",\n},\n\"license\": {\n\"name\": \"MIT license\",\n\"url\": \"https://opensource.org/licenses/MIT\",\n},\n\"termsOfService\": 'https://github.com/your-org-or-username/my-model/blob/main/LICENSE.txt',\n\"x-translator\": {\n\"component\": 'KP',\n# TODO: update the Translator team to yours\n\"team\": [ \"Clinical Data Provider\" ],\n\"biolink-version\": settings.BIOLINK_VERSION,\n\"infores\": 'infores:openpredict',\n\"externalDocs\": {\n\"description\": \"The values for component and team are restricted according to this external JSON schema. See schema and examples at url\",\n\"url\": \"https://github.com/NCATSTranslator/translator_extensions/blob/production/x-translator/\",\n},\n},\n\"x-trapi\": {\n\"version\": settings.TRAPI_VERSION,\n\"asyncquery\": False,\n\"operations\": [\n\"lookup\",\n],\n\"externalDocs\": {\n\"description\": \"The values for version are restricted according to the regex in this external JSON schema. See schema and examples at url\",\n\"url\": \"https://github.com/NCATSTranslator/translator_extensions/blob/production/x-trapi/\",\n},\n}\n}\nservers = []\nif settings.VIRTUAL_HOST:\nservers = [\n{\n\"url\": f\"https://{settings.VIRTUAL_HOST}\",\n\"description\": 'TRAPI ITRB Production Server',\n\"x-maturity\": 'production'\n},\n]\napp = TRAPI(\npredict_endpoints=predict_endpoints,\nservers=servers,\ninfo=openapi_info,\ntitle='My model TRAPI',\nversion='1.0.0',\nopenapi_version='3.0.1',\ndescription=\"\"\"Machine learning models to produce predictions that can be integrated to Translator Reasoner APIs.\n\\n\\nService supported by the [NCATS Translator project](https://ncats.nih.gov/translator/about)\"\"\",\ndev_mode=True,\n)\n</code></pre> <p>The API can then be deployed with <code>uvicorn</code> or <code>gunicorn</code> (refere to the generated project README if you used the template)</p>"},{"location":"getting-started/development/","title":"Development","text":""},{"location":"getting-started/development/#install-for-development","title":"\ud83d\udce5 Install for development","text":"<p>Clone the repository and go in the project folder:</p> <pre><code>git clone https://github.com/fair-workflows/nanopub\ncd nanopub\n</code></pre> <p>To install the project for development you can either use <code>venv</code> to create a virtual environment yourself, or use <code>hatch</code> to automatically handle virtual environments for you.</p> venvhatch <p>Create the virtual environment in the project folder :</p> <pre><code>python3 -m venv .venv\n</code></pre> <p>Activate the virtual environment:</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>Install all dependencies required for development:</p> <pre><code>pip install -e \".[dev,doc,test]\"\n</code></pre> <p>Install <code>pre-commit</code> to enable automated formatting and linting of the code at each commit:</p> <pre><code>pre-commit install\n</code></pre> <p>Install Hatch, this will automatically handle virtual environments and make sure all dependencies are installed when you run a script in the project:</p> <pre><code>pip install hatch\n</code></pre> Optionally you can improve <code>hatch</code> terminal completion <p>See the official documentation for more details. For ZSH you can run these commands:</p> <pre><code>_HATCH_COMPLETE=zsh_source hatch &gt; ~/.hatch-complete.zsh\necho \". ~/.hatch-complete.zsh\" &gt;&gt; ~/.zshrc\n</code></pre>"},{"location":"getting-started/development/#development-workflow","title":"\ud83e\uddd1\u200d\ud83d\udcbb Development workflow","text":"venvhatch <p>Try to sign a nanopublication with the code defined in <code>scripts/dev.py</code> to test your changes:</p> <pre><code>./scripts/dev.sh\n</code></pre> <p>The code will be automatically formatted when you commit your changes using <code>pre-commit</code>. But you can also run the script to format the code yourself:</p> <pre><code>./scripts/format.sh\n</code></pre> <p>Check the code for errors, and if it is in accordance with the PEP8 style guide, by running <code>flake8</code> and <code>mypy</code>:</p> <pre><code>./scripts/lint.sh\n</code></pre> <p>Try to sign a nanopublication with the code defined in <code>scripts/dev.py</code> to test your changes:</p> <pre><code>hatch run dev\n</code></pre> <p>The code will be automatically formatted when you commit your changes using <code>pre-commit</code>. But you can also run the script to format the code yourself:</p> <pre><code>hatch run format\n</code></pre> <p>Check the code for errors, and if it is in accordance with the PEP8 style guide, by running <code>flake8</code> and <code>mypy</code>:</p> <pre><code>hatch run lint\n</code></pre>"},{"location":"getting-started/development/#run-the-tests","title":"\u2705 Run the tests","text":"<p>Tests are automatically run by a GitHub Actions workflow when new code is pushed to the GitHub repository.</p> <p>The tests use the <code>nanopub-java</code> tool for validating the signing process implemented in python produces similar nanopublications. This is automatically installed by the library, just make sure <code>java</code> is available where you run the tests.</p> venvhatch <p>Run the tests locally:</p> <pre><code>./scripts/test.sh\n</code></pre> <p>You can also run only a specific test:</p> <pre><code>./scripts/test.sh tests/test_nanopub.py::test_nanopub_sign_uri\n</code></pre> <p>Run the tests locally:</p> <pre><code>hatch run test\n</code></pre> <p>You can also run only a specific test:</p> <pre><code>hatch run test tests/test_nanopub.py::test_nanopub_sign_uri\n</code></pre>"},{"location":"getting-started/development/#generate-docs","title":"\ud83d\udcd6 Generate docs","text":"<p>The documentation (this website) is automatically generated from the markdown files in the <code>docs</code> folder and python docstring comments, and published by a GitHub Actions workflow.</p> <p>Serve the docs on http://localhost:8008</p> venvhatch <pre><code>./scripts/docs.sh\n</code></pre> <pre><code>hatch run docs\n</code></pre>"},{"location":"getting-started/development/#publish-a-new-release","title":"\ud83c\udff7\ufe0f Publish a new release","text":"<ol> <li>Increment the <code>__version__</code> in <code>nanopub/_version.py</code></li> <li>Push to GitHub</li> <li>Create a new release on GitHub</li> <li>A GitHub Action workflow will automatically publish the new version to PyPI</li> </ol>"},{"location":"openpredict-api/deploy/","title":"Deploy locally","text":""},{"location":"openpredict-api/deploy/#deploy-the-openpredict-api-locally","title":"Deploy the OpenPredict API locally","text":"<p>Requirements: Python 3.8+ and <code>pip</code> installed</p> <ol> <li>Clone the repository:</li> </ol> <pre><code>git clone https://github.com/MaastrichtU-IDS/translator-openpredict.git\ncd translator-openpredict\n</code></pre> <ol> <li>Pull the data required to run the models in the <code>data</code> folder with <code>dvc</code>:</li> </ol> <pre><code>pip install dvc\ndvc pull\n</code></pre> <p>Start the API in development mode with docker on http://localhost:8808, the API will automatically reload when you make changes in the code:</p> <pre><code>docker-compose up api\n# Or with the helper script:\n./scripts/api.sh\n</code></pre> <p>Contributions are welcome! If you wish to help improve OpenPredict, see the instructions to contribute :woman_technologist: for more details on the development workflow</p>"},{"location":"openpredict-api/deploy/#test-the-openpredict-api","title":"Test the OpenPredict API","text":"<p>Run the tests locally with docker:</p> <pre><code>docker-compose run tests\n# Or with the helper script:\n./scripts/test.sh\n</code></pre> <p>See the <code>TESTING.md</code> file for more details on testing the API.</p> <p>You can change the entrypoint of the test container to run other commands, such as training a model:</p> <pre><code>docker-compose run --entrypoint \"python src/openpredict_model/train.py train-model\" tests\n# Or with the helper script:\n./scripts/run.sh python src/openpredict_model/train.py train-model\n</code></pre>"},{"location":"openpredict-api/introduction/","title":"Introduction","text":"<p>Additionally to the library, there is an example API, available at openpredict.semanticscience.org, for drug/disease predictions generated from the OpenPredict model.</p> <p>The project is structured as follow:</p> <ul> <li>the code for the OpenPredict API endpoints in  <code>src/trapi/</code> defines:<ul> <li>a TRAPI endpoint returning predictions for the loaded models</li> <li>individual endpoints for each loaded models, taking an input id, and returning predicted hits</li> <li>endpoints serving metadata about runs, models evaluations, features for the OpenPredict model, stored as RDF, using the ML Schema ontology.</li> </ul> </li> <li>various folders for different prediction models served by the OpenPredict API are available under <code>src/</code>:<ul> <li>the OpenPredict drug-disease prediction model in <code>src/openpredict_model/</code></li> <li>a model to compile the evidence path between a drug and a disease explaining the predictions of the OpenPredict model in <code>src/openpredict_evidence_path/</code></li> <li>a prediction model trained from the Drug Repurposing Knowledge Graph (aka. DRKG) in <code>src/drkg_model/</code></li> </ul> </li> </ul> <p>The data used by the models in this repository is versionned using <code>dvc</code> in the <code>data/</code> folder, and stored on DagsHub at dagshub.com/vemonet/translator-openpredict</p>"},{"location":"openpredict-api/use/","title":"Use the API","text":""},{"location":"openpredict-api/use/#use-the-openpredict-api","title":"Use the OpenPredict API","text":"<p>The user provides a drug or a disease identifier as a CURIE (e.g. DRUGBANK:DB00394, or OMIM:246300), and choose a prediction model (only the <code>Predict OMIM-DrugBank</code> classifier is currently implemented).</p> <p>The API will return predicted targets for the given drug or disease:</p> <ul> <li>The potential drugs treating a given disease :pill:</li> <li>The potential diseases a given drug could treat :microbe:</li> </ul> <p>Feel free to try the API at openpredict.semanticscience.org</p>"},{"location":"openpredict-api/use/#trapi-operations","title":"TRAPI operations","text":"<p>Operations to query OpenPredict using the Translator Reasoner API standards.</p>"},{"location":"openpredict-api/use/#query-operation","title":"Query operation","text":"<p>The <code>/query</code> operation will return the same predictions as the <code>/predict</code> operation, using the ReasonerAPI format, used within the Translator project.</p> <p>The user sends a ReasonerAPI query asking for the predicted targets given: a source, and the relation to predict. The query is a graph with nodes and edges defined in JSON, and uses classes from the BioLink model.</p> <p>You can use the default TRAPI query of OpenPredict <code>/query</code> operation to try a working example.</p> <p>Example of TRAPI query to retrieve drugs similar to a specific drug:</p> <pre><code>{\n\"message\": {\n\"query_graph\": {\n\"edges\": {\n\"e01\": {\n\"object\": \"n1\",\n\"predicates\": [\n\"biolink:similar_to\"\n],\n\"subject\": \"n0\"\n}\n},\n\"nodes\": {\n\"n0\": {\n\"categories\": [\n\"biolink:Drug\"\n],\n\"ids\": [\n\"DRUGBANK:DB00394\"\n]\n},\n\"n1\": {\n\"categories\": [\n\"biolink:Drug\"\n]\n}\n}\n}\n},\n\"query_options\": {\n\"n_results\": 3\n}\n}\n</code></pre>"},{"location":"openpredict-api/use/#predicates-operation","title":"Predicates operation","text":"<p>The <code>/predicates</code> operation will return the entities and relations provided by this API in a JSON object (following the ReasonerAPI specifications).</p> <p>Try it at https://openpredict.semanticscience.org/predicates</p>"},{"location":"openpredict-api/use/#notebooks-examples","title":"Notebooks examples","text":"<p>We provide Jupyter Notebooks with examples to use the OpenPredict API:</p> <ol> <li>Query the OpenPredict API</li> <li>Generate embeddings with pyRDF2Vec, and import them in the OpenPredict API</li> </ol>"},{"location":"openpredict-api/use/#add-embedding","title":"Add embedding","text":"<p>The default baseline model is <code>openpredict_baseline</code>. You can choose the base model when you post a new embeddings using the <code>/embeddings</code> call. Then the OpenPredict API will:</p> <ol> <li>add embeddings to the provided model</li> <li>train the model with the new embeddings</li> <li>store the features and model using a unique ID for the run (e.g. <code>7621843c-1f5f-11eb-85ae-48a472db7414</code>)</li> </ol> <p>Once the embedding has been added you can find the existing models previously generated (including <code>openpredict_baseline</code>), and use them as base model when you ask the model for prediction or add new embeddings.</p>"},{"location":"openpredict-api/use/#predict-operation","title":"Predict operation","text":"<p>Use this operation if you just want to easily retrieve predictions for a given entity. The <code>/predict</code> operation takes 4 parameters (1 required):</p> <ul> <li>A <code>drug_id</code> to get predicted diseases it could treat (e.g. <code>DRUGBANK:DB00394</code>)</li> <li>OR a <code>disease_id</code> to get predicted drugs it could be treated with (e.g. <code>OMIM:246300</code>)</li> <li>The prediction model to use (default to <code>Predict OMIM-DrugBank</code>)</li> <li>The minimum score of the returned predictions, from 0 to 1 (optional)</li> <li>The limit of results to return, starting from the higher score, e.g. 42 (optional)</li> </ul> <p>The API will return the list of predicted target for the given entity, the labels are resolved using the Translator Name Resolver API</p> <p>Try it at https://openpredict.semanticscience.org/predict?drug_id=DRUGBANK:DB00394</p>"},{"location":"openpredict-api/use/#more-about-the-data-model","title":"More about the data model","text":"<ul> <li>The gold standard for drug-disease indications has been retrieved from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3159979</li> <li>Metadata about runs, models evaluations, features are stored as RDF using the ML Schema ontology.</li> <li>See the ML Schema documentation for more details on the data model.</li> </ul> <p>Diagram of the data model used for OpenPredict, based on the ML Schema ontology (<code>mls</code>):</p> <p></p>"},{"location":"reference/trapi/","title":"TRAPI","text":"<p>         Bases: <code>FastAPI</code></p> <p>Translator Reasoner API - wrapper for FastAPI.</p> Source code in <code>openpredict/trapi.py</code> <pre><code>class TRAPI(FastAPI):\n\"\"\"Translator Reasoner API - wrapper for FastAPI.\"\"\"\nrequired_tags = [\n{\"name\": \"reasoner\"},\n{\"name\": \"trapi\"},\n{\"name\": \"models\"},\n{\"name\": \"openpredict\"},\n{\"name\": \"translator\"},\n]\ndef __init__(\nself,\n*args: Any,\npredict_endpoints: List[Callable],\nservers: Optional[List[Dict[str, str]]] = None,\ninfo: Optional[Dict[str, Any]] = None,\ntitle='Translator Reasoner API',\nversion='1.0.0',\nopenapi_version='3.0.1',\ndescription=\"\"\"Get predicted targets for a given entity\n\\n\\nService supported by the [NCATS Translator project](https://ncats.nih.gov/translator/about)\"\"\",\n**kwargs: Any,\n):\nsuper().__init__(\n*args,\ntitle=title,\nversion=version,\nopenapi_version=openapi_version,\ndescription=description,\nroot_path_in_servers=False,\n**kwargs,\n)\nself.servers = servers\nself.predict_endpoints = predict_endpoints\nself.info = info\nself.add_middleware(\nCORSMiddleware,\nallow_origins=[\"*\"],\nallow_credentials=True,\nallow_methods=[\"*\"],\nallow_headers=[\"*\"],\n)\nTRAPI_EXAMPLE = {\n\"message\": {\n\"query_graph\": {\n\"edges\": {\n\"e01\": {\n\"object\": \"n1\",\n\"predicates\": [\n\"biolink:treated_by\"\n],\n\"subject\": \"n0\"\n}\n},\n\"nodes\": {\n\"n0\": {\n\"categories\": [\n\"biolink:Disease\"\n],\n\"ids\": [\n\"OMIM:246300\",\n# \"MONDO:0007190\"\n]\n},\n\"n1\": {\n\"categories\": [\n\"biolink:Drug\"\n]\n}\n}\n}\n},\n\"query_options\": {\n\"max_score\": 1,\n\"min_score\": 0.5,\n\"n_results\": 10\n}\n}\n@self.post(\"/query\", name=\"TRAPI query\",\ndescription=\"\"\"The default example TRAPI query will give you a list of predicted potential drug treatments for a given disease\nYou can also try this query to retrieve similar entities to a given drug:\n```json\n{\n    \"message\": {\n        \"query_graph\": {\n            \"edges\": {\n                \"e01\": {\n                    \"object\": \"n1\",\n                    \"predicates\": [ \"biolink:similar_to\" ],\n                    \"subject\": \"n0\"\n                }\n            },\n            \"nodes\": {\n                \"n0\": {\n                    \"categories\": [ \"biolink:Drug\" ],\n                    \"ids\": [ \"DRUGBANK:DB00394\" ]\n                },\n                \"n1\": {\n                    \"categories\": [ \"biolink:Drug\" ]\n                }\n            }\n        }\n    },\n    \"query_options\": { \"n_results\": 5 }\n}\n```\n        \"\"\",\nresponse_model=Query,\ntags=[\"reasoner\"],\n)\ndef post_reasoner_predict(\nrequest_body: Query = Body(..., example=TRAPI_EXAMPLE)\n) -&gt; Query:\n\"\"\"Get predicted associations for a given ReasonerAPI query.\n            :param request_body: The ReasonerStdAPI query in JSON\n            :return: Predictions as a ReasonerStdAPI Message\n            \"\"\"\nquery_graph = request_body.message.query_graph.dict(exclude_none=True)\nif len(query_graph[\"edges\"]) == 0:\nreturn {\"message\": {'knowledge_graph': {'nodes': {}, 'edges': {}}, 'query_graph': query_graph, 'results': []}}\n# return ({\"status\": 400, \"title\": \"Bad Request\", \"detail\": \"No edges\", \"type\": \"about:blank\" }, 400)\nif len(query_graph[\"edges\"]) &gt; 1:\n# Currently just return a empty result if multi-edges query\nreturn {\"message\": {'knowledge_graph': {'nodes': {}, 'edges': {}}, 'query_graph': query_graph, 'results': []}}\n# return ({\"status\": 501, \"title\": \"Not Implemented\", \"detail\": \"Multi-edges queries not yet implemented\", \"type\": \"about:blank\" }, 501)\nreasonerapi_response = resolve_trapi_query(\nrequest_body.dict(exclude_none=True),\nself.predict_endpoints\n)\nreturn JSONResponse(reasonerapi_response) or ('Not found', 404)\n@self.get(\"/meta_knowledge_graph\", name=\"Get the meta knowledge graph\",\ndescription=\"Get the meta knowledge graph\",\nresponse_model=dict,\ntags=[\"trapi\"],\n)\ndef get_meta_knowledge_graph() -&gt; dict:\n\"\"\"Get predicates and entities provided by the API\n            :return: JSON with biolink entities\n            \"\"\"\nmetakg = {\n'edges': [],\n'nodes': {}\n}\nlog.info(\"IN TRAPI METAKG\")\nlog.info(self.predict_endpoints)\nprint(\"IN TRAPI METAKG\", predict_endpoints, flush=True)\nfor predict_func in self.predict_endpoints:\nif predict_func._trapi_predict['edges'] not in metakg['edges']:\nmetakg['edges'] += predict_func._trapi_predict['edges']\n# Merge nodes dict\nmetakg['nodes'] = {**metakg['nodes'], **predict_func._trapi_predict['nodes']}\nreturn JSONResponse(metakg)\n@self.middleware(\"http\")\nasync def add_process_time_header(request: Request, call_next):\nstart_time = time.time()\nresponse = await call_next(request)\nprocess_time = time.time() - start_time\nresponse.headers[\"X-Process-Time\"] = str(process_time)\nreturn response\n@self.get(\"/health\", include_in_schema=False)\ndef health_check():\n\"\"\"Health check for Translator elastic load balancer\"\"\"\nreturn {'status': 'ok'}\n@self.get(\"/\", include_in_schema=False)\ndef redirect_root_to_docs():\n\"\"\"Redirect the route / to /docs\"\"\"\nreturn RedirectResponse(url='/docs')\n# Generate endpoints for the loaded models\ndef endpoint_factory(predict_func):\ndef prediction_endpoint(\ninput_id: str = predict_func._trapi_predict['default_input'],\nmodel_id: str = predict_func._trapi_predict['default_model'],\nmin_score: float = None, max_score: float = None,\nn_results: int = None\n):\ntry:\nreturn predict_func(input_id, PredictOptions.parse_obj({\n\"model_id\": model_id,\n\"min_score\": min_score,\n\"max_score\": max_score,\n\"n_results\": n_results,\n# \"types\": ['biolink:Drug'],\n}))\nexcept Exception as e:\nimport traceback\nprint(traceback.format_exc())\nreturn (f'Error when running the prediction: {e}', 500)\nreturn prediction_endpoint\nfor predict_func in self.predict_endpoints:\nself.add_api_route(\npath=predict_func._trapi_predict['path'],\nmethods=[\"GET\"],\n# endpoint=copy_func(prediction_endpoint, model['path'].replace('/', '')),\nendpoint=endpoint_factory(predict_func),\nname=predict_func._trapi_predict['name'],\nopenapi_extra={\"description\": predict_func._trapi_predict['description']},\nresponse_model=dict,\ntags=[\"models\"],\n)\ndef openapi(self) -&gt; Dict[str, Any]:\n\"\"\"Build custom OpenAPI schema.\"\"\"\nif self.openapi_schema:\nreturn self.openapi_schema\ntags = self.required_tags\nif self.openapi_tags:\ntags += self.openapi_tags\nopenapi_schema = get_openapi(\n# **self.info,\ntitle=self.title,\nversion=self.version,\nopenapi_version=self.openapi_version,\ndescription=self.description,\nroutes=self.routes,\ntags=tags,\n)\nopenapi_schema[\"servers\"] = self.servers\nopenapi_schema[\"info\"] = {**openapi_schema[\"info\"], **self.info}\nself.openapi_schema = openapi_schema\nreturn self.openapi_schema\n</code></pre>"},{"location":"reference/trapi/#openpredict.trapi.TRAPI.__init__","title":"<code>__init__(*args, predict_endpoints, servers=None, info=None, title='Translator Reasoner API', version='1.0.0', openapi_version='3.0.1', description='Get predicted targets for a given entity\\n\\n\\nService supported by the [NCATS Translator project](https://ncats.nih.gov/translator/about)', **kwargs)</code>","text":"Source code in <code>openpredict/trapi.py</code> <pre><code>    def __init__(\nself,\n*args: Any,\npredict_endpoints: List[Callable],\nservers: Optional[List[Dict[str, str]]] = None,\ninfo: Optional[Dict[str, Any]] = None,\ntitle='Translator Reasoner API',\nversion='1.0.0',\nopenapi_version='3.0.1',\ndescription=\"\"\"Get predicted targets for a given entity\n\\n\\nService supported by the [NCATS Translator project](https://ncats.nih.gov/translator/about)\"\"\",\n**kwargs: Any,\n):\nsuper().__init__(\n*args,\ntitle=title,\nversion=version,\nopenapi_version=openapi_version,\ndescription=description,\nroot_path_in_servers=False,\n**kwargs,\n)\nself.servers = servers\nself.predict_endpoints = predict_endpoints\nself.info = info\nself.add_middleware(\nCORSMiddleware,\nallow_origins=[\"*\"],\nallow_credentials=True,\nallow_methods=[\"*\"],\nallow_headers=[\"*\"],\n)\nTRAPI_EXAMPLE = {\n\"message\": {\n\"query_graph\": {\n\"edges\": {\n\"e01\": {\n\"object\": \"n1\",\n\"predicates\": [\n\"biolink:treated_by\"\n],\n\"subject\": \"n0\"\n}\n},\n\"nodes\": {\n\"n0\": {\n\"categories\": [\n\"biolink:Disease\"\n],\n\"ids\": [\n\"OMIM:246300\",\n# \"MONDO:0007190\"\n]\n},\n\"n1\": {\n\"categories\": [\n\"biolink:Drug\"\n]\n}\n}\n}\n},\n\"query_options\": {\n\"max_score\": 1,\n\"min_score\": 0.5,\n\"n_results\": 10\n}\n}\n@self.post(\"/query\", name=\"TRAPI query\",\ndescription=\"\"\"The default example TRAPI query will give you a list of predicted potential drug treatments for a given disease\nYou can also try this query to retrieve similar entities to a given drug:\n```json\n{\n    \"message\": {\n        \"query_graph\": {\n            \"edges\": {\n                \"e01\": {\n                    \"object\": \"n1\",\n                    \"predicates\": [ \"biolink:similar_to\" ],\n                    \"subject\": \"n0\"\n                }\n            },\n            \"nodes\": {\n                \"n0\": {\n                    \"categories\": [ \"biolink:Drug\" ],\n                    \"ids\": [ \"DRUGBANK:DB00394\" ]\n                },\n                \"n1\": {\n                    \"categories\": [ \"biolink:Drug\" ]\n                }\n            }\n        }\n    },\n    \"query_options\": { \"n_results\": 5 }\n}\n```\n        \"\"\",\nresponse_model=Query,\ntags=[\"reasoner\"],\n)\ndef post_reasoner_predict(\nrequest_body: Query = Body(..., example=TRAPI_EXAMPLE)\n) -&gt; Query:\n\"\"\"Get predicted associations for a given ReasonerAPI query.\n            :param request_body: The ReasonerStdAPI query in JSON\n            :return: Predictions as a ReasonerStdAPI Message\n            \"\"\"\nquery_graph = request_body.message.query_graph.dict(exclude_none=True)\nif len(query_graph[\"edges\"]) == 0:\nreturn {\"message\": {'knowledge_graph': {'nodes': {}, 'edges': {}}, 'query_graph': query_graph, 'results': []}}\n# return ({\"status\": 400, \"title\": \"Bad Request\", \"detail\": \"No edges\", \"type\": \"about:blank\" }, 400)\nif len(query_graph[\"edges\"]) &gt; 1:\n# Currently just return a empty result if multi-edges query\nreturn {\"message\": {'knowledge_graph': {'nodes': {}, 'edges': {}}, 'query_graph': query_graph, 'results': []}}\n# return ({\"status\": 501, \"title\": \"Not Implemented\", \"detail\": \"Multi-edges queries not yet implemented\", \"type\": \"about:blank\" }, 501)\nreasonerapi_response = resolve_trapi_query(\nrequest_body.dict(exclude_none=True),\nself.predict_endpoints\n)\nreturn JSONResponse(reasonerapi_response) or ('Not found', 404)\n@self.get(\"/meta_knowledge_graph\", name=\"Get the meta knowledge graph\",\ndescription=\"Get the meta knowledge graph\",\nresponse_model=dict,\ntags=[\"trapi\"],\n)\ndef get_meta_knowledge_graph() -&gt; dict:\n\"\"\"Get predicates and entities provided by the API\n            :return: JSON with biolink entities\n            \"\"\"\nmetakg = {\n'edges': [],\n'nodes': {}\n}\nlog.info(\"IN TRAPI METAKG\")\nlog.info(self.predict_endpoints)\nprint(\"IN TRAPI METAKG\", predict_endpoints, flush=True)\nfor predict_func in self.predict_endpoints:\nif predict_func._trapi_predict['edges'] not in metakg['edges']:\nmetakg['edges'] += predict_func._trapi_predict['edges']\n# Merge nodes dict\nmetakg['nodes'] = {**metakg['nodes'], **predict_func._trapi_predict['nodes']}\nreturn JSONResponse(metakg)\n@self.middleware(\"http\")\nasync def add_process_time_header(request: Request, call_next):\nstart_time = time.time()\nresponse = await call_next(request)\nprocess_time = time.time() - start_time\nresponse.headers[\"X-Process-Time\"] = str(process_time)\nreturn response\n@self.get(\"/health\", include_in_schema=False)\ndef health_check():\n\"\"\"Health check for Translator elastic load balancer\"\"\"\nreturn {'status': 'ok'}\n@self.get(\"/\", include_in_schema=False)\ndef redirect_root_to_docs():\n\"\"\"Redirect the route / to /docs\"\"\"\nreturn RedirectResponse(url='/docs')\n# Generate endpoints for the loaded models\ndef endpoint_factory(predict_func):\ndef prediction_endpoint(\ninput_id: str = predict_func._trapi_predict['default_input'],\nmodel_id: str = predict_func._trapi_predict['default_model'],\nmin_score: float = None, max_score: float = None,\nn_results: int = None\n):\ntry:\nreturn predict_func(input_id, PredictOptions.parse_obj({\n\"model_id\": model_id,\n\"min_score\": min_score,\n\"max_score\": max_score,\n\"n_results\": n_results,\n# \"types\": ['biolink:Drug'],\n}))\nexcept Exception as e:\nimport traceback\nprint(traceback.format_exc())\nreturn (f'Error when running the prediction: {e}', 500)\nreturn prediction_endpoint\nfor predict_func in self.predict_endpoints:\nself.add_api_route(\npath=predict_func._trapi_predict['path'],\nmethods=[\"GET\"],\n# endpoint=copy_func(prediction_endpoint, model['path'].replace('/', '')),\nendpoint=endpoint_factory(predict_func),\nname=predict_func._trapi_predict['name'],\nopenapi_extra={\"description\": predict_func._trapi_predict['description']},\nresponse_model=dict,\ntags=[\"models\"],\n)\n</code></pre>"},{"location":"reference/trapi/#openpredict.trapi.TRAPI.openapi","title":"<code>openapi()</code>","text":"<p>Build custom OpenAPI schema.</p> Source code in <code>openpredict/trapi.py</code> <pre><code>def openapi(self) -&gt; Dict[str, Any]:\n\"\"\"Build custom OpenAPI schema.\"\"\"\nif self.openapi_schema:\nreturn self.openapi_schema\ntags = self.required_tags\nif self.openapi_tags:\ntags += self.openapi_tags\nopenapi_schema = get_openapi(\n# **self.info,\ntitle=self.title,\nversion=self.version,\nopenapi_version=self.openapi_version,\ndescription=self.description,\nroutes=self.routes,\ntags=tags,\n)\nopenapi_schema[\"servers\"] = self.servers\nopenapi_schema[\"info\"] = {**openapi_schema[\"info\"], **self.info}\nself.openapi_schema = openapi_schema\nreturn self.openapi_schema\n</code></pre>"}]}