{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Getting started","text":"<p>OpenPredict is a python package that helps data scientists to build, and publish prediction models in a FAIR and reproducible manner. It provides helpers for various steps of the process:</p> <ul> <li>A template to help user quickly bootstrap a new prediction project with the recommended structure (MaastrichtU-IDS/cookiecutter-openpredict-api)</li> <li>Helper function to easily save a generated model, its metadata, and the data used to generate it. It uses tools such as <code>dvc</code> and <code>mlem</code> to store large model outside of the git repository.</li> <li>Deploy API endpoints for retrieving predictions, which comply with the NCATS Biomedical Data Translator standards (Translator Reasoner API and BioLink model), using a decorator <code>@trapi_predict</code> to simply annotate the function that produces predicted associations for a given input entity</li> </ul> <p>Predictions are usually generated from machine learning models (e.g. predict disease treated by drug), but it can adapt to generic python function, as long as the input params and return object follow the expected structure.</p>"},{"location":"#installation","title":"Installation","text":"<p>To start a new project to develop and publish models for predictions we recommend to use the cookiecutter template that bootstrap, see the page create a model for more details.</p> <p>Otherwise the <code>openpredict</code> package can be installed with <code>pip</code>:</p> <pre><code>pip install openpredict\n</code></pre>"},{"location":"#acknowledgments","title":"Acknowledgments\u200b","text":"<p>This service has been built from the fair-workflows/openpredict project. And Predictions of the OpenPredict API made using the PREDICT method.</p> <p>This service is funded by the NIH NCATS Translator project.</p> <p></p>"},{"location":"getting-started/create-model/","title":"Creating a prediction model","text":""},{"location":"getting-started/create-model/#save-a-generated-model","title":"\ud83d\udcbe Save a generated model","text":"<p>Once you have setup your project it is time to start defining your model training. We recommend to do this in a specific file, e.g. <code>train.py</code></p> <p>A helper function is provided to easily save a generated model, its metadata, and the data used to generate it. It uses tools such as <code>dvc</code> and <code>mlem</code> to store large model outside of the git repository. Here is an example:</p> <pre><code>from openpredict import save\nhyper_params = {\n'penalty': 'l2',\n'dual': False,\n'tol': 0.0001,\n'C': 1.0,\n'random_state': 100\n}\nsaved_model = save(\nmodel=clf,\npath=\"models/my_model\",\nsample_data=sample_data,\nhyper_params=hyper_params,\nscores=scores,\n)\n</code></pre> <p>If you generated a project from the template you will find it in the <code>train.py</code> script.</p> <p>\u26a0\ufe0f Once you have trained your model don\u2019t forget to add it, usually in the <code>models/</code> folder, and push it with <code>dvc</code> (along with all the data required to train the model in the <code>data/</code> folder)</p>"},{"location":"getting-started/create-model/#define-the-prediction-endpoint","title":"\ud83d\udd2e Define the prediction endpoint","text":"<p>Once your model has been trained you can create a function taking an input ID and generating predictions for it. We recommend to do it in a specific file, e.g. <code>predict.py</code></p> <p>The <code>openpredict</code> package provides a decorator <code>@trapi_predict</code> to annotate your functions that generate predictions. Predictions generated from functions decorated with <code>@trapi_predict</code> can easily be imported in the Translator OpenPredict API, exposed as an API endpoint to get predictions from the web, and queried through the Translator Reasoner API (TRAPI).</p> <p>The annotated predict functions are expected to take 2 input arguments: the input ID (string) and options for the prediction (dictionary). And it should return a dictionary with a list of predicted associated entities hits (see below for a practical example)</p> <p>Here is an example:</p> <pre><code>from openpredict import trapi_predict, PredictOptions, PredictOutput\n@trapi_predict(path='/predict',\nname=\"Get predicted targets for a given entity\",\ndescription=\"Return the predicted targets for a given entity: drug (DrugBank ID) or disease (OMIM ID), with confidence scores.\",\nedges=[\n{\n'subject': 'biolink:Drug',\n'predicate': 'biolink:treats',\n'object': 'biolink:Disease',\n},\n{\n'subject': 'biolink:Disease',\n'predicate': 'biolink:treated_by',\n'object': 'biolink:Drug',\n},\n],\nnodes={\n\"biolink:Disease\": {\n\"id_prefixes\": [\n\"OMIM\"\n]\n},\n\"biolink:Drug\": {\n\"id_prefixes\": [\n\"DRUGBANK\"\n]\n}\n}\n)\ndef get_predictions(\ninput_id: str, options: PredictOptions\n) -&gt; PredictOutput:\n# Add the code the load the model and get predictions here\npredictions = {\n\"hits\": [\n{\n\"id\": \"DB00001\",\n\"type\": \"biolink:Drug\",\n\"score\": 0.12345,\n\"label\": \"Leipirudin\",\n}\n],\n\"count\": 1,\n}\nreturn predictions\n</code></pre> <p>If you generated a project from the template you will find it in the <code>predict.py</code> script.</p>"},{"location":"getting-started/create-project/","title":"Creating a project","text":""},{"location":"getting-started/create-project/#start-a-new-prediction-project","title":"\ud83c\udf6a Start a new prediction project","text":"<p>We recommend to bootstrap your project using our template, it will generate all required files to get started with an example training and prediction workflow.</p> <p>Run these commands to install <code>cookiecutter</code> and generate your project from the template:</p> <pre><code>pip install cookiecutter\ncookiecutter https://github.com/MaastrichtU-IDS/cookiecutter-openpredict-api\n</code></pre> <p>\u2139\ufe0f Once your project has been generated, checkout the generated <code>README.md</code> for the instructions on how to run your project in development.</p>"},{"location":"getting-started/create-project/#enter-the-development-environment","title":"\ud83d\udeaa Enter the development environment","text":"<p>Use <code>hatch shell</code> to enter a virtual environment for development with all required dependencies installed. Once in the environment you will be able to use commands such as <code>dvc</code></p> <pre><code>hatch shell\n</code></pre>"},{"location":"getting-started/create-project/#setup-data-version-control","title":"\ud83d\udd0e Setup data version control","text":"<p><code>openpredict</code> uses <code>dvc</code> for data version control, it helps you to easily store datasets used by your machine learning workflows that are too big for git, and keep track of changes in a way similar to git. And similarly to git, with dvc you will need to choose a platform to publish your data, such as DagsHub or HuggingFace.</p> <p>Here we document the process using DagsHub to publish data related to a ML experiment, but you could choose to use a different platform for your project if you wish.</p> <p>\u26a0\ufe0f Open source projects on DagsHub using the free plan have a 10G storage limit.</p> <ol> <li> <p>Go to dagshub.com, and login with GitHub or Google</p> </li> <li> <p>Create a new project in DagsHub by connecting it to the GitHub repository with the code for the experiment (this repository)</p> </li> <li> <p>Set your DagsHub credentials in your local terminal (add these commands to your <code>~/.bashrc</code> or <code>~/.zshrc</code> to enable it automatically on boot):</p> </li> </ol> <pre><code>export DAGSHUB_USER=\"your-org-or-username\"\nexport DAGSHUB_TOKEN=\"TOKEN\"\n</code></pre> <ol> <li>Link your local repository to the created DagsHub project:</li> </ol> <pre><code>dvc remote add origin https://dagshub.com/$DAGSHUB_USER/openpredict-model.dvc\ndvc remote default origin\ndvc remote modify origin --local auth basic\ndvc remote modify origin --local user $DAGSHUB_USER\ndvc remote modify origin --local password $DAGSHUB_TOKEN\n</code></pre>"},{"location":"getting-started/create-project/#push-data","title":"Push data","text":"<p>\u26a0\ufe0f Put all data files required to train the model, and the files generated by the training to the <code>data/</code> folder and publish this data to the remote repository</p> <p>You can check the status <code>dvc</code> in the current repository with:</p> <pre><code>dvc status\n</code></pre> <p>First add the changes made to the <code>data/</code> folder:</p> <pre><code>dvc add data\n</code></pre> <p>Then push the added data:</p> <pre><code>dvc push\n</code></pre> <p>Alternatively you can use this shortcut to add changes and push in one command:</p> <pre><code>hatch run push-data\n</code></pre>"},{"location":"getting-started/create-project/#pull-data","title":"Pull data","text":"<p>To retrieve all data from the remote repository:</p> <pre><code>dvc pull\n</code></pre>"},{"location":"getting-started/create-project/#run-in-development","title":"\ud83e\ude84 Run in development","text":"<p>You are free to setup your development workflow as you wish, consider those instructions as recommendations which work out-of-the-box with the code generated by the template.</p> <p>Note that scripts executed with <code>hatch run</code> are defined in the <code>pyproject.toml</code> file, feel free to check it out and change them as needed.</p>"},{"location":"getting-started/create-project/#deploy-api-and-train","title":"Deploy API and train","text":"<p>Deploy  your prediction function as a Translator Reasoner API on http://localhost:8808</p> <pre><code>hatch -v run api\n</code></pre> <p>Run the script to train the model:</p> <pre><code>hatch run train\n</code></pre>"},{"location":"getting-started/create-project/#test","title":"Test","text":"<p>Run the tests defined in the <code>tests/</code> folder locally:</p> <pre><code>hatch run test -s\n</code></pre>"},{"location":"getting-started/create-project/#add-dependencies","title":"Add dependencies","text":"<p>Add dependencies directly in the <code>pyproject.toml</code>. Try to keep the main dependencies minimal: just what is needed to run the predictions functions. And add all dependencies required for training in the <code>train</code> optional dependencies.</p> <p>Hatch will automatically update the virtual environment the next time you use it to run a script.</p> <p>If you are facing issue with the dependencies (e.g. not updated properly), you can reset the environment with:</p> <pre><code>hatch env prune\n</code></pre>"},{"location":"getting-started/create-project/#run-with-docker","title":"\ud83d\udc33 Run with docker","text":"<p>You can also run the training script in docker, see the <code>docker-compose.yml</code> if you need to change the command to execute the script:</p> <pre><code>docker-compose run training\n</code></pre> <p>Or start the TRAPI API:</p> <pre><code>docker-compose up api\n</code></pre> <p>Or start a JupyterLab/VSCode workspace on http://localhost:8888:</p> <pre><code>docker-compose up workspace\n</code></pre>"},{"location":"getting-started/deploy-api/","title":"Deploying the API","text":""},{"location":"getting-started/deploy-api/#define-the-api","title":"Define the API","text":"<p>You will need to instantiate a <code>TRAPI</code> class to deploy a Translator Reasoner API serving a list of prediction functions that have been decorated with <code>@trapi_predict</code>. For example:</p> <pre><code>import logging\nfrom openpredict.config import settings\nfrom openpredict import TRAPI\nfrom my_model.predict import get_predictions\nlog_level = logging.ERROR\nif settings.DEV_MODE:\nlog_level = logging.INFO\nlogging.basicConfig(level=log_level)\npredict_endpoints = [ get_predictions ]\nopenapi_info = {\n\"contact\": {\n\"name\": \"Firstname Lastname\",\n\"email\": \"email@example.com\",\n# \"x-id\": \"https://orcid.org/0000-0000-0000-0000\",\n\"x-role\": \"responsible developer\",\n},\n\"license\": {\n\"name\": \"MIT license\",\n\"url\": \"https://opensource.org/licenses/MIT\",\n},\n\"termsOfService\": 'https://github.com/your-org-or-username/my-model/blob/main/LICENSE.txt',\n\"x-translator\": {\n\"component\": 'KP',\n# TODO: update the Translator team to yours\n\"team\": [ \"Clinical Data Provider\" ],\n\"biolink-version\": settings.BIOLINK_VERSION,\n\"infores\": 'infores:openpredict',\n\"externalDocs\": {\n\"description\": \"The values for component and team are restricted according to this external JSON schema. See schema and examples at url\",\n\"url\": \"https://github.com/NCATSTranslator/translator_extensions/blob/production/x-translator/\",\n},\n},\n\"x-trapi\": {\n\"version\": settings.TRAPI_VERSION,\n\"asyncquery\": False,\n\"operations\": [\n\"lookup\",\n],\n\"externalDocs\": {\n\"description\": \"The values for version are restricted according to the regex in this external JSON schema. See schema and examples at url\",\n\"url\": \"https://github.com/NCATSTranslator/translator_extensions/blob/production/x-trapi/\",\n},\n}\n}\nservers = []\nif settings.VIRTUAL_HOST:\nservers = [\n{\n\"url\": f\"https://{settings.VIRTUAL_HOST}\",\n\"description\": 'TRAPI ITRB Production Server',\n\"x-maturity\": 'production'\n},\n]\napp = TRAPI(\npredict_endpoints=predict_endpoints,\nservers=servers,\ninfo=openapi_info,\ntitle='My model TRAPI',\nversion='1.0.0',\nopenapi_version='3.0.1',\ndescription=\"\"\"Machine learning models to produce predictions that can be integrated to Translator Reasoner APIs.\n\\n\\nService supported by the [NCATS Translator project](https://ncats.nih.gov/translator/about)\"\"\",\ndev_mode=True,\n)\n</code></pre>"},{"location":"getting-started/deploy-api/#deploy-the-api","title":"Deploy the API","text":"<p>If you used the template to generate your project you can deploy the API with the <code>api</code> script defined in the <code>pyproject.toml</code> (refere to your generated project README for more details):</p> <pre><code>hatch run api\n</code></pre> <p>Otherwise you can use <code>uvicorn</code> or <code>gunicorn</code>:</p> <pre><code>uvicorn trapi.main:app --port 8808 --reload\n</code></pre>"},{"location":"getting-started/development/","title":"Development","text":""},{"location":"getting-started/development/#install-for-development","title":"\ud83d\udce5 Install for development","text":"<p>Clone the repository and go in the project folder:</p> <pre><code>git clone https://github.com/fair-workflows/nanopub\ncd nanopub\n</code></pre> <p>To install the project for development you can either use <code>venv</code> to create a virtual environment yourself, or use <code>hatch</code> to automatically handle virtual environments for you.</p> venvhatch <p>Create the virtual environment in the project folder :</p> <pre><code>python3 -m venv .venv\n</code></pre> <p>Activate the virtual environment:</p> <pre><code>source .venv/bin/activate\n</code></pre> <p>Install all dependencies required for development:</p> <pre><code>pip install -e \".[dev,doc,test]\"\n</code></pre> <p>Install <code>pre-commit</code> to enable automated formatting and linting of the code at each commit:</p> <pre><code>pre-commit install\n</code></pre> <p>Install Hatch, this will automatically handle virtual environments and make sure all dependencies are installed when you run a script in the project:</p> <pre><code>pip install hatch\n</code></pre> Optionally you can improve <code>hatch</code> terminal completion <p>See the official documentation for more details. For ZSH you can run these commands:</p> <pre><code>_HATCH_COMPLETE=zsh_source hatch &gt; ~/.hatch-complete.zsh\necho \". ~/.hatch-complete.zsh\" &gt;&gt; ~/.zshrc\n</code></pre>"},{"location":"getting-started/development/#development-workflow","title":"\ud83e\uddd1\u200d\ud83d\udcbb Development workflow","text":"venvhatch <p>Try to sign a nanopublication with the code defined in <code>scripts/dev.py</code> to test your changes:</p> <pre><code>./scripts/dev.sh\n</code></pre> <p>The code will be automatically formatted when you commit your changes using <code>pre-commit</code>. But you can also run the script to format the code yourself:</p> <pre><code>./scripts/format.sh\n</code></pre> <p>Check the code for errors, and if it is in accordance with the PEP8 style guide, by running <code>flake8</code> and <code>mypy</code>:</p> <pre><code>./scripts/lint.sh\n</code></pre> <p>Try to sign a nanopublication with the code defined in <code>scripts/dev.py</code> to test your changes:</p> <pre><code>hatch run dev\n</code></pre> <p>The code will be automatically formatted when you commit your changes using <code>pre-commit</code>. But you can also run the script to format the code yourself:</p> <pre><code>hatch run format\n</code></pre> <p>Check the code for errors, and if it is in accordance with the PEP8 style guide, by running <code>flake8</code> and <code>mypy</code>:</p> <pre><code>hatch run lint\n</code></pre>"},{"location":"getting-started/development/#run-the-tests","title":"\u2705 Run the tests","text":"<p>Tests are automatically run by a GitHub Actions workflow when new code is pushed to the GitHub repository.</p> <p>The tests use the <code>nanopub-java</code> tool for validating the signing process implemented in python produces similar nanopublications. This is automatically installed by the library, just make sure <code>java</code> is available where you run the tests.</p> venvhatch <p>Run the tests locally:</p> <pre><code>./scripts/test.sh\n</code></pre> <p>You can also run only a specific test:</p> <pre><code>./scripts/test.sh tests/test_nanopub.py::test_nanopub_sign_uri\n</code></pre> <p>Run the tests locally:</p> <pre><code>hatch run test\n</code></pre> <p>You can also run only a specific test:</p> <pre><code>hatch run test tests/test_nanopub.py::test_nanopub_sign_uri\n</code></pre>"},{"location":"getting-started/development/#generate-docs","title":"\ud83d\udcd6 Generate docs","text":"<p>The documentation (this website) is automatically generated from the markdown files in the <code>docs</code> folder and python docstring comments, and published by a GitHub Actions workflow.</p> <p>Serve the docs on http://localhost:8008</p> venvhatch <pre><code>./scripts/docs.sh\n</code></pre> <pre><code>hatch run docs\n</code></pre>"},{"location":"getting-started/development/#publish-a-new-release","title":"\ud83c\udff7\ufe0f Publish a new release","text":"<ol> <li>Increment the <code>__version__</code> in <code>nanopub/_version.py</code></li> <li>Push to GitHub</li> <li>Create a new release on GitHub</li> <li>A GitHub Action workflow will automatically publish the new version to PyPI</li> </ol>"},{"location":"openpredict-api/deploy/","title":"Deploying locally","text":""},{"location":"openpredict-api/deploy/#deploy-the-openpredict-api-locally","title":"Deploy the OpenPredict API locally","text":"<p>Requirements: Python 3.8+ and <code>pip</code> installed</p> <ol> <li>Clone the repository:</li> </ol> <pre><code>git clone https://github.com/MaastrichtU-IDS/translator-openpredict.git\ncd translator-openpredict\n</code></pre> <ol> <li>Pull the data required to run the models in the <code>data</code> folder with <code>dvc</code>:</li> </ol> <pre><code>pip install dvc\ndvc pull\n</code></pre> <p>Start the API in development mode with docker on http://localhost:8808, the API will automatically reload when you make changes in the code:</p> <pre><code>docker-compose up api\n# Or with the helper script:\n./scripts/api.sh\n</code></pre> <p>Contributions are welcome! If you wish to help improve OpenPredict, see the instructions to contribute :woman_technologist: for more details on the development workflow</p>"},{"location":"openpredict-api/deploy/#test-the-openpredict-api","title":"Test the OpenPredict API","text":"<p>Run the tests locally with docker:</p> <pre><code>docker-compose run tests\n# Or with the helper script:\n./scripts/test.sh\n</code></pre> <p>See the <code>TESTING.md</code> file for more details on testing the API.</p> <p>You can change the entrypoint of the test container to run other commands, such as training a model:</p> <pre><code>docker-compose run --entrypoint \"python src/openpredict_model/train.py train-model\" tests\n# Or with the helper script:\n./scripts/run.sh python src/openpredict_model/train.py train-model\n</code></pre>"},{"location":"openpredict-api/introduction/","title":"Introduction","text":"<p>Additionally to the library, there is an example API, available at openpredict.semanticscience.org, for drug/disease predictions generated from the OpenPredict model.</p> <p>The project is structured as follow:</p> <ul> <li>the code for the OpenPredict API endpoints in  <code>src/trapi/</code> defines:<ul> <li>a TRAPI endpoint returning predictions for the loaded models</li> <li>individual endpoints for each loaded models, taking an input id, and returning predicted hits</li> <li>endpoints serving metadata about runs, models evaluations, features for the OpenPredict model, stored as RDF, using the ML Schema ontology.</li> </ul> </li> <li>various folders for different prediction models served by the OpenPredict API are available under <code>src/</code>:<ul> <li>the OpenPredict drug-disease prediction model in <code>src/openpredict_model/</code></li> <li>a model to compile the evidence path between a drug and a disease explaining the predictions of the OpenPredict model in <code>src/openpredict_evidence_path/</code></li> <li>a prediction model trained from the Drug Repurposing Knowledge Graph (aka. DRKG) in <code>src/drkg_model/</code></li> </ul> </li> </ul> <p>The data used by the models in this repository is versionned using <code>dvc</code> in the <code>data/</code> folder, and stored on DagsHub at dagshub.com/vemonet/translator-openpredict</p>"},{"location":"openpredict-api/use/","title":"Using the API","text":""},{"location":"openpredict-api/use/#use-the-openpredict-api","title":"Use the OpenPredict API","text":"<p>The user provides a drug or a disease identifier as a CURIE (e.g. DRUGBANK:DB00394, or OMIM:246300), and choose a prediction model (only the <code>Predict OMIM-DrugBank</code> classifier is currently implemented).</p> <p>The API will return predicted targets for the given drug or disease:</p> <ul> <li>The potential drugs treating a given disease :pill:</li> <li>The potential diseases a given drug could treat :microbe:</li> </ul> <p>Feel free to try the API at openpredict.semanticscience.org</p>"},{"location":"openpredict-api/use/#trapi-operations","title":"TRAPI operations","text":"<p>Operations to query OpenPredict using the Translator Reasoner API standards.</p>"},{"location":"openpredict-api/use/#query-operation","title":"Query operation","text":"<p>The <code>/query</code> operation will return the same predictions as the <code>/predict</code> operation, using the ReasonerAPI format, used within the Translator project.</p> <p>The user sends a ReasonerAPI query asking for the predicted targets given: a source, and the relation to predict. The query is a graph with nodes and edges defined in JSON, and uses classes from the BioLink model.</p> <p>You can use the default TRAPI query of OpenPredict <code>/query</code> operation to try a working example.</p> <p>Example of TRAPI query to retrieve drugs similar to a specific drug:</p> <pre><code>{\n\"message\": {\n\"query_graph\": {\n\"edges\": {\n\"e01\": {\n\"object\": \"n1\",\n\"predicates\": [\n\"biolink:similar_to\"\n],\n\"subject\": \"n0\"\n}\n},\n\"nodes\": {\n\"n0\": {\n\"categories\": [\n\"biolink:Drug\"\n],\n\"ids\": [\n\"DRUGBANK:DB00394\"\n]\n},\n\"n1\": {\n\"categories\": [\n\"biolink:Drug\"\n]\n}\n}\n}\n},\n\"query_options\": {\n\"n_results\": 3\n}\n}\n</code></pre>"},{"location":"openpredict-api/use/#predicates-operation","title":"Predicates operation","text":"<p>The <code>/predicates</code> operation will return the entities and relations provided by this API in a JSON object (following the ReasonerAPI specifications).</p> <p>Try it at https://openpredict.semanticscience.org/predicates</p>"},{"location":"openpredict-api/use/#notebooks-examples","title":"Notebooks examples","text":"<p>We provide Jupyter Notebooks with examples to use the OpenPredict API:</p> <ol> <li>Query the OpenPredict API</li> <li>Generate embeddings with pyRDF2Vec, and import them in the OpenPredict API</li> </ol>"},{"location":"openpredict-api/use/#add-embedding","title":"Add embedding","text":"<p>The default baseline model is <code>openpredict_baseline</code>. You can choose the base model when you post a new embeddings using the <code>/embeddings</code> call. Then the OpenPredict API will:</p> <ol> <li>add embeddings to the provided model</li> <li>train the model with the new embeddings</li> <li>store the features and model using a unique ID for the run (e.g. <code>7621843c-1f5f-11eb-85ae-48a472db7414</code>)</li> </ol> <p>Once the embedding has been added you can find the existing models previously generated (including <code>openpredict_baseline</code>), and use them as base model when you ask the model for prediction or add new embeddings.</p>"},{"location":"openpredict-api/use/#predict-operation","title":"Predict operation","text":"<p>Use this operation if you just want to easily retrieve predictions for a given entity. The <code>/predict</code> operation takes 4 parameters (1 required):</p> <ul> <li>A <code>drug_id</code> to get predicted diseases it could treat (e.g. <code>DRUGBANK:DB00394</code>)</li> <li>OR a <code>disease_id</code> to get predicted drugs it could be treated with (e.g. <code>OMIM:246300</code>)</li> <li>The prediction model to use (default to <code>Predict OMIM-DrugBank</code>)</li> <li>The minimum score of the returned predictions, from 0 to 1 (optional)</li> <li>The limit of results to return, starting from the higher score, e.g. 42 (optional)</li> </ul> <p>The API will return the list of predicted target for the given entity, the labels are resolved using the Translator Name Resolver API</p> <p>Try it at https://openpredict.semanticscience.org/predict?drug_id=DRUGBANK:DB00394</p>"},{"location":"openpredict-api/use/#more-about-the-data-model","title":"More about the data model","text":"<ul> <li>The gold standard for drug-disease indications has been retrieved from https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3159979</li> <li>Metadata about runs, models evaluations, features are stored as RDF using the ML Schema ontology.</li> <li>See the ML Schema documentation for more details on the data model.</li> </ul> <p>Diagram of the data model used for OpenPredict, based on the ML Schema ontology (<code>mls</code>):</p> <p></p>"},{"location":"reference/trapi/","title":"TRAPI","text":"<p>         Bases: <code>FastAPI</code></p> <p>Translator Reasoner API - wrapper for FastAPI.</p> Source code in <code>/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/openpredict/trapi.py</code> <pre><code>class TRAPI(FastAPI):\n\"\"\"Translator Reasoner API - wrapper for FastAPI.\"\"\"\nrequired_tags = [\n{\"name\": \"reasoner\"},\n{\"name\": \"trapi\"},\n{\"name\": \"models\"},\n{\"name\": \"openpredict\"},\n{\"name\": \"translator\"},\n]\ndef __init__(\nself,\n*args: Any,\npredict_endpoints: List[Callable],\nservers: Optional[List[Dict[str, str]]] = None,\ninfo: Optional[Dict[str, Any]] = None,\ntitle='Translator Reasoner API',\nversion='1.0.0',\nopenapi_version='3.0.1',\ndescription=\"\"\"Get predicted targets for a given entity\n\\n\\nService supported by the [NCATS Translator project](https://ncats.nih.gov/translator/about)\"\"\",\n**kwargs: Any,\n):\nsuper().__init__(\n*args,\ntitle=title,\nversion=version,\nopenapi_version=openapi_version,\ndescription=description,\nroot_path_in_servers=False,\n**kwargs,\n)\nself.servers = servers\nself.predict_endpoints = predict_endpoints\nself.info = info\nself.add_middleware(\nCORSMiddleware,\nallow_origins=[\"*\"],\nallow_credentials=True,\nallow_methods=[\"*\"],\nallow_headers=[\"*\"],\n)\nTRAPI_EXAMPLE = {\n\"message\": {\n\"query_graph\": {\n\"edges\": {\n\"e01\": {\n\"object\": \"n1\",\n\"predicates\": [\n\"biolink:treated_by\"\n],\n\"subject\": \"n0\"\n}\n},\n\"nodes\": {\n\"n0\": {\n\"categories\": [\n\"biolink:Disease\"\n],\n\"ids\": [\n\"OMIM:246300\",\n# \"MONDO:0007190\"\n]\n},\n\"n1\": {\n\"categories\": [\n\"biolink:Drug\"\n]\n}\n}\n}\n},\n\"query_options\": {\n\"max_score\": 1,\n\"min_score\": 0.5,\n\"n_results\": 10\n}\n}\n@self.post(\"/query\", name=\"TRAPI query\",\ndescription=\"\"\"The default example TRAPI query will give you a list of predicted potential drug treatments for a given disease\nYou can also try this query to retrieve similar entities to a given drug:\n```json\n{\n    \"message\": {\n        \"query_graph\": {\n            \"edges\": {\n                \"e01\": {\n                    \"object\": \"n1\",\n                    \"predicates\": [ \"biolink:similar_to\" ],\n                    \"subject\": \"n0\"\n                }\n            },\n            \"nodes\": {\n                \"n0\": {\n                    \"categories\": [ \"biolink:Drug\" ],\n                    \"ids\": [ \"DRUGBANK:DB00394\" ]\n                },\n                \"n1\": {\n                    \"categories\": [ \"biolink:Drug\" ]\n                }\n            }\n        }\n    },\n    \"query_options\": { \"n_results\": 5 }\n}\n```\n        \"\"\",\nresponse_model=Query,\ntags=[\"reasoner\"],\n)\ndef post_reasoner_predict(\nrequest_body: Query = Body(..., example=TRAPI_EXAMPLE)\n) -&gt; Query:\n\"\"\"Get predicted associations for a given ReasonerAPI query.\n            :param request_body: The ReasonerStdAPI query in JSON\n            :return: Predictions as a ReasonerStdAPI Message\n            \"\"\"\nquery_graph = request_body.message.query_graph.dict(exclude_none=True)\nif len(query_graph[\"edges\"]) == 0:\nreturn {\"message\": {'knowledge_graph': {'nodes': {}, 'edges': {}}, 'query_graph': query_graph, 'results': []}}\n# return ({\"status\": 400, \"title\": \"Bad Request\", \"detail\": \"No edges\", \"type\": \"about:blank\" }, 400)\nif len(query_graph[\"edges\"]) &gt; 1:\n# Currently just return a empty result if multi-edges query\nreturn {\"message\": {'knowledge_graph': {'nodes': {}, 'edges': {}}, 'query_graph': query_graph, 'results': []}}\n# return ({\"status\": 501, \"title\": \"Not Implemented\", \"detail\": \"Multi-edges queries not yet implemented\", \"type\": \"about:blank\" }, 501)\nreasonerapi_response = resolve_trapi_query(\nrequest_body.dict(exclude_none=True),\nself.predict_endpoints\n)\nreturn JSONResponse(reasonerapi_response) or ('Not found', 404)\n@self.get(\"/meta_knowledge_graph\", name=\"Get the meta knowledge graph\",\ndescription=\"Get the meta knowledge graph\",\nresponse_model=dict,\ntags=[\"trapi\"],\n)\ndef get_meta_knowledge_graph() -&gt; dict:\n\"\"\"Get predicates and entities provided by the API\n            :return: JSON with biolink entities\n            \"\"\"\nmetakg = {\n'edges': [],\n'nodes': {}\n}\nlog.info(\"IN TRAPI METAKG\")\nlog.info(self.predict_endpoints)\nprint(\"IN TRAPI METAKG\", predict_endpoints, flush=True)\nfor predict_func in self.predict_endpoints:\nif predict_func._trapi_predict['edges'] not in metakg['edges']:\nmetakg['edges'] += predict_func._trapi_predict['edges']\n# Merge nodes dict\nmetakg['nodes'] = {**metakg['nodes'], **predict_func._trapi_predict['nodes']}\nreturn JSONResponse(metakg)\n@self.middleware(\"http\")\nasync def add_process_time_header(request: Request, call_next):\nstart_time = time.time()\nresponse = await call_next(request)\nprocess_time = time.time() - start_time\nresponse.headers[\"X-Process-Time\"] = str(process_time)\nreturn response\n@self.get(\"/health\", include_in_schema=False)\ndef health_check():\n\"\"\"Health check for Translator elastic load balancer\"\"\"\nreturn {'status': 'ok'}\n@self.get(\"/\", include_in_schema=False)\ndef redirect_root_to_docs():\n\"\"\"Redirect the route / to /docs\"\"\"\nreturn RedirectResponse(url='/docs')\n# Generate endpoints for the loaded models\ndef endpoint_factory(predict_func):\ndef prediction_endpoint(\ninput_id: str = predict_func._trapi_predict['default_input'],\nmodel_id: str = predict_func._trapi_predict['default_model'],\nmin_score: float = None, max_score: float = None,\nn_results: int = None\n):\ntry:\nreturn predict_func(input_id, PredictOptions.parse_obj({\n\"model_id\": model_id,\n\"min_score\": min_score,\n\"max_score\": max_score,\n\"n_results\": n_results,\n# \"types\": ['biolink:Drug'],\n}))\nexcept Exception as e:\nimport traceback\nprint(traceback.format_exc())\nreturn (f'Error when running the prediction: {e}', 500)\nreturn prediction_endpoint\nfor predict_func in self.predict_endpoints:\nself.add_api_route(\npath=predict_func._trapi_predict['path'],\nmethods=[\"GET\"],\n# endpoint=copy_func(prediction_endpoint, model['path'].replace('/', '')),\nendpoint=endpoint_factory(predict_func),\nname=predict_func._trapi_predict['name'],\nopenapi_extra={\"description\": predict_func._trapi_predict['description']},\nresponse_model=dict,\ntags=[\"models\"],\n)\ndef openapi(self) -&gt; Dict[str, Any]:\n\"\"\"Build custom OpenAPI schema.\"\"\"\nif self.openapi_schema:\nreturn self.openapi_schema\ntags = self.required_tags\nif self.openapi_tags:\ntags += self.openapi_tags\nopenapi_schema = get_openapi(\n# **self.info,\ntitle=self.title,\nversion=self.version,\nopenapi_version=self.openapi_version,\ndescription=self.description,\nroutes=self.routes,\ntags=tags,\n)\nopenapi_schema[\"servers\"] = self.servers\nopenapi_schema[\"info\"] = {**openapi_schema[\"info\"], **self.info}\nself.openapi_schema = openapi_schema\nreturn self.openapi_schema\n</code></pre>"},{"location":"reference/trapi/#openpredict.trapi.TRAPI.__init__","title":"<code>__init__(*args, predict_endpoints, servers=None, info=None, title='Translator Reasoner API', version='1.0.0', openapi_version='3.0.1', description='Get predicted targets for a given entity\\n\\n\\nService supported by the [NCATS Translator project](https://ncats.nih.gov/translator/about)', **kwargs)</code>","text":"Source code in <code>/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/openpredict/trapi.py</code> <pre><code>    def __init__(\nself,\n*args: Any,\npredict_endpoints: List[Callable],\nservers: Optional[List[Dict[str, str]]] = None,\ninfo: Optional[Dict[str, Any]] = None,\ntitle='Translator Reasoner API',\nversion='1.0.0',\nopenapi_version='3.0.1',\ndescription=\"\"\"Get predicted targets for a given entity\n\\n\\nService supported by the [NCATS Translator project](https://ncats.nih.gov/translator/about)\"\"\",\n**kwargs: Any,\n):\nsuper().__init__(\n*args,\ntitle=title,\nversion=version,\nopenapi_version=openapi_version,\ndescription=description,\nroot_path_in_servers=False,\n**kwargs,\n)\nself.servers = servers\nself.predict_endpoints = predict_endpoints\nself.info = info\nself.add_middleware(\nCORSMiddleware,\nallow_origins=[\"*\"],\nallow_credentials=True,\nallow_methods=[\"*\"],\nallow_headers=[\"*\"],\n)\nTRAPI_EXAMPLE = {\n\"message\": {\n\"query_graph\": {\n\"edges\": {\n\"e01\": {\n\"object\": \"n1\",\n\"predicates\": [\n\"biolink:treated_by\"\n],\n\"subject\": \"n0\"\n}\n},\n\"nodes\": {\n\"n0\": {\n\"categories\": [\n\"biolink:Disease\"\n],\n\"ids\": [\n\"OMIM:246300\",\n# \"MONDO:0007190\"\n]\n},\n\"n1\": {\n\"categories\": [\n\"biolink:Drug\"\n]\n}\n}\n}\n},\n\"query_options\": {\n\"max_score\": 1,\n\"min_score\": 0.5,\n\"n_results\": 10\n}\n}\n@self.post(\"/query\", name=\"TRAPI query\",\ndescription=\"\"\"The default example TRAPI query will give you a list of predicted potential drug treatments for a given disease\nYou can also try this query to retrieve similar entities to a given drug:\n```json\n{\n    \"message\": {\n        \"query_graph\": {\n            \"edges\": {\n                \"e01\": {\n                    \"object\": \"n1\",\n                    \"predicates\": [ \"biolink:similar_to\" ],\n                    \"subject\": \"n0\"\n                }\n            },\n            \"nodes\": {\n                \"n0\": {\n                    \"categories\": [ \"biolink:Drug\" ],\n                    \"ids\": [ \"DRUGBANK:DB00394\" ]\n                },\n                \"n1\": {\n                    \"categories\": [ \"biolink:Drug\" ]\n                }\n            }\n        }\n    },\n    \"query_options\": { \"n_results\": 5 }\n}\n```\n        \"\"\",\nresponse_model=Query,\ntags=[\"reasoner\"],\n)\ndef post_reasoner_predict(\nrequest_body: Query = Body(..., example=TRAPI_EXAMPLE)\n) -&gt; Query:\n\"\"\"Get predicted associations for a given ReasonerAPI query.\n            :param request_body: The ReasonerStdAPI query in JSON\n            :return: Predictions as a ReasonerStdAPI Message\n            \"\"\"\nquery_graph = request_body.message.query_graph.dict(exclude_none=True)\nif len(query_graph[\"edges\"]) == 0:\nreturn {\"message\": {'knowledge_graph': {'nodes': {}, 'edges': {}}, 'query_graph': query_graph, 'results': []}}\n# return ({\"status\": 400, \"title\": \"Bad Request\", \"detail\": \"No edges\", \"type\": \"about:blank\" }, 400)\nif len(query_graph[\"edges\"]) &gt; 1:\n# Currently just return a empty result if multi-edges query\nreturn {\"message\": {'knowledge_graph': {'nodes': {}, 'edges': {}}, 'query_graph': query_graph, 'results': []}}\n# return ({\"status\": 501, \"title\": \"Not Implemented\", \"detail\": \"Multi-edges queries not yet implemented\", \"type\": \"about:blank\" }, 501)\nreasonerapi_response = resolve_trapi_query(\nrequest_body.dict(exclude_none=True),\nself.predict_endpoints\n)\nreturn JSONResponse(reasonerapi_response) or ('Not found', 404)\n@self.get(\"/meta_knowledge_graph\", name=\"Get the meta knowledge graph\",\ndescription=\"Get the meta knowledge graph\",\nresponse_model=dict,\ntags=[\"trapi\"],\n)\ndef get_meta_knowledge_graph() -&gt; dict:\n\"\"\"Get predicates and entities provided by the API\n            :return: JSON with biolink entities\n            \"\"\"\nmetakg = {\n'edges': [],\n'nodes': {}\n}\nlog.info(\"IN TRAPI METAKG\")\nlog.info(self.predict_endpoints)\nprint(\"IN TRAPI METAKG\", predict_endpoints, flush=True)\nfor predict_func in self.predict_endpoints:\nif predict_func._trapi_predict['edges'] not in metakg['edges']:\nmetakg['edges'] += predict_func._trapi_predict['edges']\n# Merge nodes dict\nmetakg['nodes'] = {**metakg['nodes'], **predict_func._trapi_predict['nodes']}\nreturn JSONResponse(metakg)\n@self.middleware(\"http\")\nasync def add_process_time_header(request: Request, call_next):\nstart_time = time.time()\nresponse = await call_next(request)\nprocess_time = time.time() - start_time\nresponse.headers[\"X-Process-Time\"] = str(process_time)\nreturn response\n@self.get(\"/health\", include_in_schema=False)\ndef health_check():\n\"\"\"Health check for Translator elastic load balancer\"\"\"\nreturn {'status': 'ok'}\n@self.get(\"/\", include_in_schema=False)\ndef redirect_root_to_docs():\n\"\"\"Redirect the route / to /docs\"\"\"\nreturn RedirectResponse(url='/docs')\n# Generate endpoints for the loaded models\ndef endpoint_factory(predict_func):\ndef prediction_endpoint(\ninput_id: str = predict_func._trapi_predict['default_input'],\nmodel_id: str = predict_func._trapi_predict['default_model'],\nmin_score: float = None, max_score: float = None,\nn_results: int = None\n):\ntry:\nreturn predict_func(input_id, PredictOptions.parse_obj({\n\"model_id\": model_id,\n\"min_score\": min_score,\n\"max_score\": max_score,\n\"n_results\": n_results,\n# \"types\": ['biolink:Drug'],\n}))\nexcept Exception as e:\nimport traceback\nprint(traceback.format_exc())\nreturn (f'Error when running the prediction: {e}', 500)\nreturn prediction_endpoint\nfor predict_func in self.predict_endpoints:\nself.add_api_route(\npath=predict_func._trapi_predict['path'],\nmethods=[\"GET\"],\n# endpoint=copy_func(prediction_endpoint, model['path'].replace('/', '')),\nendpoint=endpoint_factory(predict_func),\nname=predict_func._trapi_predict['name'],\nopenapi_extra={\"description\": predict_func._trapi_predict['description']},\nresponse_model=dict,\ntags=[\"models\"],\n)\n</code></pre>"},{"location":"reference/trapi/#openpredict.trapi.TRAPI.openapi","title":"<code>openapi()</code>","text":"<p>Build custom OpenAPI schema.</p> Source code in <code>/opt/hostedtoolcache/Python/3.9.17/x64/lib/python3.9/site-packages/openpredict/trapi.py</code> <pre><code>def openapi(self) -&gt; Dict[str, Any]:\n\"\"\"Build custom OpenAPI schema.\"\"\"\nif self.openapi_schema:\nreturn self.openapi_schema\ntags = self.required_tags\nif self.openapi_tags:\ntags += self.openapi_tags\nopenapi_schema = get_openapi(\n# **self.info,\ntitle=self.title,\nversion=self.version,\nopenapi_version=self.openapi_version,\ndescription=self.description,\nroutes=self.routes,\ntags=tags,\n)\nopenapi_schema[\"servers\"] = self.servers\nopenapi_schema[\"info\"] = {**openapi_schema[\"info\"], **self.info}\nself.openapi_schema = openapi_schema\nreturn self.openapi_schema\n</code></pre>"}]}