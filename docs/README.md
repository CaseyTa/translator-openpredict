[![Version](https://img.shields.io/pypi/v/openpredict)](https://pypi.org/project/openpredict) [![Python versions](https://img.shields.io/pypi/pyversions/openpredict)](https://pypi.org/project/openpredict) [![Run tests](https://github.com/MaastrichtU-IDS/translator-openpredict/workflows/Run%20tests/badge.svg)](https://github.com/MaastrichtU-IDS/translator-openpredict/actions?query=workflow%3A%22Run+tests%22) [![Publish package](https://github.com/MaastrichtU-IDS/translator-openpredict/workflows/Publish%20package/badge.svg)](https://github.com/MaastrichtU-IDS/translator-openpredict/actions?query=workflow%3A%22Publish+package%22) [![SonarCloud Quality Gate Status](https://sonarcloud.io/api/project_badges/measure?project=MaastrichtU-IDS_translator-openpredict&metric=alert_status)](https://sonarcloud.io/dashboard?id=MaastrichtU-IDS_translator-openpredict) [![SonarCloud Maintainability Rating](https://sonarcloud.io/api/project_badges/measure?project=MaastrichtU-IDS_translator-openpredict&metric=sqale_rating)](https://sonarcloud.io/dashboard?id=MaastrichtU-IDS_translator-openpredict) [![SonarCloud Coverage](https://sonarcloud.io/api/project_badges/measure?project=MaastrichtU-IDS_translator-openpredict&metric=coverage)](https://sonarcloud.io/dashboard?id=MaastrichtU-IDS_translator-openpredict)

Additional documentation to develop the **Translator OpenPredict API**.

> Contributions, [feedbacks](https://github.com/MaastrichtU-IDS/translator-openpredict/issues) and pull requests are welcomed!

This repository uses [GitHub Actions](https://github.com/MaastrichtU-IDS/translator-openpredict/actions) to:

* Automatically run tests at each push to the `master` branch
* Publish the [OpenPredict package to PyPI](https://pypi.org/project/openpredict/) when a release is created (N.B.: the version of the package needs to be increased in [setup.py](https://github.com/MaastrichtU-IDS/translator-openpredict/blob/master/setup.py#L6) before).

**See [here](https://github.com/MaastrichtU-IDS/translator-openpredict/tree/master/docs/README-pydoc.md) to browse the Python code documentation** automatically generated by [pydoc-markdown](https://pydoc-markdown.readthedocs.io/en/latest/) 📖

# Example notebooks

We provide [Jupyter Notebooks](https://jupyter.org/) with examples to use the OpenPredict API in this `docs` folder:

1. [Query the OpenPredict API](https://github.com/MaastrichtU-IDS/translator-openpredict/blob/master/docs/openpredict-examples.ipynb)
2. [Generate embeddings with pyRDF2Vec](https://github.com/MaastrichtU-IDS/translator-openpredict/blob/master/docs/openpredict-pyrdf2vec-embeddings.ipynb), and import them in the OpenPredict API

The notebook to generate embeddings requires to have Spark installed, you can use it with the `jupyter/all-spark-notebook` image easily with our `docker-compose.yml`:

```bash
cd docs
docker-compose up
```

> Default password is `password`

# Alternatives to install OpenPredict

### Install from PyPI

Install the latest release published on [PyPI 🏷️](https://pypi.org/project/openpredict) (or see below to [run the API with Docker](#option-3-run-with-docker))

```bash
pip3 install openpredict
```

> It is currently recommended to install from the source code to get the latest version

# Alternatives to run OpenPredict

Requirements: 

* [Docker](https://docs.docker.com/get-docker/) installed (and `docker-compose`)
* Python 3.6+

See the main README.md if you just want to OpenPredict locally, this documentation is for people who wants to use a specific triplestore, or try out new way to run OpenPredict

### Use Virtuoso as local triplestore

1. Create the data folder:

   ```bash
   mkdir -p data
   ```

2. **Start the Virtuoso database** locally on http://localhost:8890 using Docker (login: `dba` / `dba`):

```bash
docker-compose -f docker-compose.dev.yml up -d --force-recreate
```

3. **Start the OpenPredict API** on http://localhost:8808 (wait 30s for the database to start first):

```bash
openpredict start-api
```

> Contributions are welcome! If you wish to help improve OpenPredict, see the [instructions to contribute :woman_technologist:](/CONTRIBUTING.md)

Once you finished you can stop the Virtuoso container, and restart it later. The data will be stored in `data/virtuoso`

```bash
docker-compose down
```

### Define environment variables locally

OpenPredict can be configured using environment variables in your local terminal:

* triplestore credentials
* path you want to be used as directory to store models and features files. By default it will do it in a `data` folder in the directory where you started the OpenPredict API.

```bash
export SPARQL_ENDPOINT_URL=https://graphdb.dumontierlab.com/repositories/translator-openpredict-dev
export SPARQL_ENDPOINT_UPDATE_URL=https://graphdb.dumontierlab.com/repositories/translator-openpredict-dev/statements
export SPARQL_USER=import_user
export SPARQL_PASSWORD=password
export OPENPREDICT_APIKEY=myapikey
export OPENPREDICT_DATA_DIR=/data/openpredict
```

> You can add those exports to your `~/.bashrc` or `~/.zshrc` file to define it permanently.

The OpenPredict API can deployed in 3 different ways:

### Option 1: Run from the command line ⌨️

Use the `openpredict` CLI to run in development with [Flask 🧪](https://flask.palletsprojects.com/en/1.1.x/). The API will reload automatically at each change 🔃

```bash
openpredict start-api --debug
```

You can also start the API in production settings using [Tornado 🌪️](https://www.tornadoweb.org/en/stable/)

```bash
openpredict start-api
```

> Access the Swagger UI at [http://localhost:8808](http://localhost:8808)

You can provide the API port as argument:

```bash
openpredict start-api --port 8808
```

### Option 2: Run from a Python script 🐍

```python
from openpredict import openpredict_api

openpredict_api.start_api(8808)
```

> Access the Swagger UI at [http://localhost:8808](http://localhost:8808)

> Run by default in production, set `debug = True` to run in development environments. 

### Option 3: Run with Docker 🐳

Running using Docker can be convenient if you just want to run the API without installing the package locally, or if it runs in production alongside other services.

Clone the [repository](https://github.com/MaastrichtU-IDS/translator-openpredict):

```bash
git clone https://github.com/MaastrichtU-IDS/translator-openpredict.git
cd translator-openpredict
```

1. For **development environments**: see above to use the default `docker-compose.yml` file to deploy the Virtuoso triplestore for development using Docker 
2. For **production deployment** use the `docker-compose.prod.yml`

> The docker-compose is currently configured to deploy on [openpredict.semanticscience.org](https://openpredict.semanticscience.org/) using a [nginx-proxy for Docker](https://github.com/nginx-proxy)

Define the triplestore credentials and API key in the `.env` file 🔑

```bash
nano .env
SPARQL_USER=import_user
SPARQL_PASSWORD=password
```

Start the API in production using GraphDB as backend:

```bash
docker-compose up -d
```

> We use a [nginx-proxy for Docker](https://github.com/nginx-proxy/nginx-proxy) and [docker-letsencrypt-nginx-proxy-companion](https://github.com/nginx-proxy/docker-letsencrypt-nginx-proxy-companion) as reverse proxy for HTTP and HTTPS in production. You can change the proxy URL and port via environment variables `VIRTUAL_HOST`, `VIRTUAL_PORT` and `LETSENCRYPT_HOST` in the [docker-compose.yml](https://github.com/MaastrichtU-IDS/translator-openpredict/blob/master/docker-compose.yml) file.

Check the logs:

```bash
docker-compose logs
```

Stop the container:

```bash
docker-compose down
```

# Build the OpenPredict API Docker image

Build, but make sure the tests passes first!

```bash
docker build -t ghcr.io/maastrichtu-ids/openpredict-api:latest .
```

Push to the [MaastrichtU-IDS GitHub Container Registry 📦](https://github.com/orgs/MaastrichtU-IDS/packages/container/package/openpredict-api)

```bash
docker push ghcr.io/maastrichtu-ids/openpredict-api:latest
```
